{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries and modules\n",
    "We will be using the following modules and libraries in our program:\n",
    "\n",
    "- **math** - to access special mathematical functions\n",
    "- **csv** - to create the submission file\n",
    "- **collections** - to use specialized container data types\n",
    "- **pandas** - to perform some data manipulation\n",
    "- **NumPy**  - to work efficiently with large arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python standard library modules\n",
    "import math\n",
    "import csv\n",
    "import collections\n",
    "\n",
    "# Open-source, BSD-licensed libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Subclass of the built-in Python dictionary that provides a default value for a non-existent key\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set number of rows to be displayed\n",
    "This pertains to the number of rows displayed when the data are presented in tabular form using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of rows to be displayed\n",
    "NUM_ROWS = 2000\n",
    "\n",
    "pd.set_option('display.max_rows', NUM_ROWS)\n",
    "pd.set_option('display.min_rows', NUM_ROWS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for processing\n",
    "Before going to the core of the problem, we have to perform some preliminaries to make the actual data processing phase more systematic and efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the dataset\n",
    "The first step is, of course, to load the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = pd.read_csv('order_brush_order.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a good idea to manipulate a **copy** of the dataset in order to avoid modifying the contents of the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_raw.copy(deep = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We display the data in tabular form to check if the dataset has been loaded successfully. This also gives us an initial idea of its contents, the format or manner in which they are stored, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Remove duplicate rows\n",
    "Since each transaction is assigned a unique orderid, we discard duplicates in our dataset since they are most likely instances of misrecording or misencoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We display the data (with duplicates removed) in tabular form. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the number of rows after performing duplication removal is the same as in the previous step. \n",
    "In other words, there are no duplicate entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sort data\n",
    "The idea behind sorting the data comes from the problem statement:\n",
    "- We are interested in the instances of order brushing **per shop**.\n",
    "- For each shop, we need to identify **time windows** when order brushing was conducted.\n",
    "\n",
    "Therefore, we perform two-stage sorting: based on the shop IDs first, then based on the timestamps of the transactions (from earliest to latest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(by = ['shopid', 'event_time'], inplace = True, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We display the sorted data in tabular form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Convert event_time to datetime object\n",
    "Since we are interested in identifying one-hour intervals, we need to convert the entries in the event_time column into actual datetime objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicit specification of format speeds up execution time.\n",
    "data['event_time'] = pd.to_datetime(data['event_time'], format = '%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check if the conversion is successful by printing the data type of the first event_time entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(data.at[0, 'event_time']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create NumPy arrays for the columns\n",
    "Our algorithm hinges on iterating over the rows of the dataset. However, doing this with pandas is an anti-pattern, significantly slowing down the execution time of our program. Therefore, it is more efficient if we process the columns as parallel NumPy arrays instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy array for orderid\n",
    "orderid_list = data['orderid'].to_numpy()\n",
    "\n",
    "# NumPy array for shopid\n",
    "shopid_list = data['shopid'].to_numpy()\n",
    "\n",
    "# NumPy array for userid\n",
    "userid_list = data['userid'].to_numpy()\n",
    "\n",
    "# NumPy array for event_time\n",
    "event_time_list = data['event_time'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check if the NumPy arrays have been successfully created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(orderid_list))\n",
    "print(type(shopid_list))\n",
    "print(type(userid_list))\n",
    "print(type(event_time_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all the preliminary preparations finished, we now proceed to the core of the order brushing detection task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set the \"constants\"\n",
    "Setting \"constants\" is a good programming practice that discards so-called \"magic numbers,\" which greatly detract code readability. In addition, it makes our program more maintainable and flexible to changes.\n",
    "\n",
    "Based on the problem statement:\n",
    "- Order brushing must be checked for every one-hour window (1 hour = 3600 seconds).\n",
    "- Order brushing is conducted if the concentration rate is at least 3.0\n",
    "\n",
    "Note that, if there are $n$ entries, then the maximum concentration rate is $n$, which occurs when all the orders come from a single buyer. Therefore, the minimum number of entries needed to reach a concentration rate of at least $x$ is $\\lceil x \\rceil$, the least integer that is greater than or equal to $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of seconds in a possible order brushing period\n",
    "BRUSH_NUM_SECONDS = 3600\n",
    "\n",
    "# Minimum concentration rate for order brushing\n",
    "BRUSH_CONCEN_RATE = 3.0\n",
    "\n",
    "# Minimum number of entries for order brushing\n",
    "BRUSH_NUM_ENTRIES = math.ceil(BRUSH_CONCEN_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create some functions\n",
    "Following the \"divide-and-conquer\" approach in programming, functions help make our program more modular. Note that these functions take advantage of the fact that the data have already been sorted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Function that creates the array containing the indices of the first entries per shop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameter:**\n",
    "- *shopid_list* is the array containing the shop IDs in the dataset\n",
    "\n",
    "**Return:**\n",
    "- array containing the indices of the first entries per shop\n",
    "\n",
    "Since this function is also used to determine the indices of the last entries per shop, a \"dummy shop\" was added at the end in order to get the index of the last entry of the last shop. Therefore, the last element of the array returned by this function is (the index of the last entry of the last shop + 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_shopgrp_idx_list(shopid_list):\n",
    "    shopgrp_idx_list = np.flatnonzero(np.concatenate(([True], shopid_list[1:] != shopid_list[:-1])))\n",
    "    shopgrp_idx_list = np.concatenate((shopgrp_idx_list, [len(shopid_list)]))\n",
    "    \n",
    "    return shopgrp_idx_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite its brevity, the algorithm presented in this function &mdash; which takes advantage of the efficiency of NumPy functions &mdash; is not immediately intuitive. Hence, we expound on the logic behind its implementation:\n",
    "\n",
    "*First line in the function body*\n",
    "- Perform an element-by-element comparison of shopid_list excluding the first element and shopid_list excluding the last element. \n",
    "- Since we are interested in the indices of the first entries per shop, we check for **inequality**. If they are not equal, then the result of this comparison is *True*; otherwise, the result is *False*. \n",
    "- Store the results in an array.\n",
    "- Prepend *True* to this array to account for the first entry of the first shop.\n",
    "- Note that the indices of the *True* elements correspond to the indices of the first entries per shop. \n",
    "- Store these indices in an array using the NumPy flatnonzero() function (*True* is a nonzero value in programming).\n",
    "\n",
    "*Second line in the function body*\n",
    "- Add the \"dummy shop.\" Since the index of the last entry of the last shop is (the number of elements in shopid_list &ndash; 1), the index of the first entry of this \"dummy shop\" is equal to the number of elements in shopid_list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Function that checks if the start time and end time are within a given number of seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameters:**\n",
    "- *start_time* is the start time\n",
    "- *end_time* is the end time\n",
    "- *num_seconds* is the maximum difference between the start time and end time (in terms of seconds)\n",
    "\n",
    "**Return:**\n",
    "- *True*, if the start and end time are within the given number of seconds\n",
    "- *False*, otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_within_time(start_time, end_time, num_seconds):\n",
    "    \n",
    "    # Since event_time_list is a NumPy array, the number of seconds has to be converted to a NumPy timedelta object.\n",
    "    return end_time - start_time <= np.timedelta64(num_seconds, 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Function that computes the concentration rate in a given period "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameters:**\n",
    "- *userid_list* is the array containing the user IDs of the buyers in the dataset\n",
    "- *start_time_idx* is the index of the start time\n",
    "- *end_time_idx* is the index of the end time\n",
    "\n",
    "**Return:**\n",
    "- concentration rate in the given period:\n",
    "$$\\text{concentration rate} = \\dfrac{\\text{number of orders}}{\\text{number of unique users}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concen_rate(userid_list, start_time_idx, end_time_idx):\n",
    "    \n",
    "    # Count the number of unique users.\n",
    "    num_unique_users = len(np.unique(userid_list[start_time_idx : end_time_idx + 1]))\n",
    "    \n",
    "    # Count the number of orders.\n",
    "    num_orders = end_time_idx - start_time_idx + 1 \n",
    "    \n",
    "    # Compute and return the concentration rate.\n",
    "    return num_orders / num_unique_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Function that checks if a given period is a possible order brushing period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precondition:**\n",
    "- Assume that the start time and end time are within the time window for a possible order brushing period.\n",
    "- Assume that the index of the start time is greater than the index of the first entry of the current shop. **(The case when the indices are equal is handled in the main program routine.)**\n",
    "\n",
    "**Parameters:**\n",
    "- *event_time_list* is the array containing the timestamps in the dataset\n",
    "- *start_time_idx* is the index of the start time\n",
    "- *end_time_idx* is the index of the end time\n",
    "- *next_shopgrp_idx* is the index of the first entry of the next shop\n",
    "- *brush_num_seconds* is the number of seconds in a possible order brushing period\n",
    "\n",
    "**Return:**\n",
    "- *True*, if the given period is a possible order brushing period\n",
    "- *False*, otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_possible_brush_time(event_time_list, start_time_idx, end_time_idx, next_shopgrp_idx, brush_num_seconds):\n",
    "    \n",
    "    # It is important to evaluate the first expression before evaluating the second one.\n",
    "    # Otherwise, we will run into the error of accessing an element outside the bounds of the current shop.\n",
    "    return end_time_idx == next_shopgrp_idx - 1 \\\n",
    "        or not is_within_time(event_time_list[start_time_idx - 1], event_time_list[end_time_idx + 1], brush_num_seconds + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite its brevity, this is arguably the most difficult subroutine to write. The challenge is to determine if a given period constitutes an order brushing period *without checking through all possible 1-hour windows*. Hence, we expound on the logic behind its implementation.\n",
    "\n",
    "We begin by introducing some notation to formalize our logic:\n",
    "- <b>start_time<sub>order</sub></b> is the start time referred to *by default*, i.e., the time of the first order in the one-hour period being investigated.\n",
    "- <b>end_time<sub>order</sub></b> is the end time referred to *by default*, i.e., the time of the last order in the one-hour period being investigated.\n",
    "- <b>start_time<sub>order &ndash; 1 </sub></b> is the time of the order immediately before the order referred to in start_time<sub>order</sub>, *provided it exists.*\n",
    "- <b>end_time<sub>order + 1 </sub></b> is the time of the order immediately after the order referred to in end_time<sub>order</sub>, *provided it exists.*\n",
    "- <b>start_time<sub>true</sub></b> is the start time of the one-hour period being investigated.\n",
    "- <b>end_time<sub>true</sub></b> is the end time of the one-hour period being investigated.\n",
    "\n",
    "The following conditions should hold true:\n",
    "- <b>start_time<sub>order &ndash; 1</sub> < start_time<sub>true</sub> &#8804; start_time<sub>order</sub> < end_time<sub>order</sub> &#8804; end_time<sub>true</sub> < end_time<sub>order + 1</sub></b>\n",
    "- <b>start_time<sub>order</sub> and end_time<sub>order</sub> are within one hour.</b> This is a precondition for calling this function, so we do not need to worry about this.\n",
    "- <b>start_time<sub>true</sub> and end_time<sub>true</sub> are within one hour.</b>\n",
    "\n",
    "The function returns *True* if at least one of these conditions holds true:\n",
    "- <b>end_time<sub>order</sub> is the timestamp of the last entry of the current shop.</b> This takes care of the case when end_time<sub>order + 1</sub> does not exist. Thanks to the precondition, setting start_time<sub>true</sub> = start_time<sub>order</sub> and setting end_time<sub>true</sub> to 1 hour after start_time<sub>true</sub> will satisfy the conditions above.\n",
    "\n",
    "\n",
    "- <b>start_time<sub>order &ndash; 1</sub> and end_time<sub>order + 1</sub> are not within one hour and one second.</b> end_time<sub>true</sub> < end_time<sub>order + 1 </sub> implies that end_time<sub>order + 1 </sub> is one second after end_time<sub>true</sub> at the earliest. Analogously, start_time<sub>order &ndash; 1</sub> < start_time<sub>true</sub> implies that start_time<sub>order &ndash; 1</sub> is one second before start_time<sub>true</sub> at the latest. Taking into account that the difference between start_time<sub>true</sub> and end_time<sub>true</sub> is at most 3600 seconds, it follows that the difference between start_time<sub>order &ndash; 1</sub> and end_time<sub>order + 1 </sub> is at least 3602 seconds.\n",
    "\n",
    "\n",
    "Note that this logic still holds even if we change the length of the time window. Reiterating the second precondition, the case when start_time<sub> order &ndash; 1</sub> does not exist is deferred to the main program routine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. Function that checks if a given concentration rate meets the minimum for order brushing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameters:**\n",
    "- *concen_rate* is the given concentration rate\n",
    "- *brush_concen_rate* is the minimum concentration rate for order brushing\n",
    "\n",
    "**Return:**\n",
    "- *True*, if the given concentration rate meets the minimum for order brushing\n",
    "- *False*, otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_order_brushing(concen_rate, brush_concen_rate):\n",
    "    return concen_rate >= brush_concen_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f. Function that identifies the suspicious buyers in a shop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameter:**\n",
    "- *transact_dict* is the dictionary containing the user IDs as keys and the list of associated order IDs as values\n",
    "\n",
    "**Return:**\n",
    "- list of the user IDs of the suspicious buyers in an order brushing shop\n",
    "- [0], if the shop is not found to have conducted order brushing\n",
    "\n",
    "The suspicious buyers in an order brushing shop refer to those who ordered the highest number of products during order brushing periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_suspicious(transact_dict):\n",
    "    \n",
    "    # An empty transact_dict implies that the shop is not found to have conducted order brushing.\n",
    "    if not transact_dict:\n",
    "        suspicious_list = [0]\n",
    "    \n",
    "    else:\n",
    "        # Get the highest number of products ordered by a single user.\n",
    "        max_num_orders = 0\n",
    "        for orders in transact_dict.values():\n",
    "            if len(orders) > max_num_orders:\n",
    "                max_num_orders = len(orders)\n",
    "\n",
    "        # Get the user IDs of the suspicious buyers.\n",
    "        suspicious_list = [userid for userid, orders in transact_dict.items() if len(orders) == max_num_orders]\n",
    "\n",
    "        # The task specifies that the user IDs of the suspicious buyers should be listed in ascending order.\n",
    "        if len(suspicious_list) > 1:\n",
    "            suspicious_list.sort()\n",
    "    \n",
    "    return suspicious_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### g. Function that assigns the suspicious buyers to the master shop dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameters:**\n",
    "- *shop_dict* is the master shop dictionary containing the shop IDs as keys and the list of associated suspicious buyers as values\n",
    "- *suspicious_list* is the list of the user IDs of the suspicious buyers in an order brushing shop ([0] if the shop is not found to have conducted order brushing)\n",
    "- *shopid_list* is the list of shop IDs in the dataset\n",
    "- *curr_shopgrp_idx* is the index of the first entry of the current shop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_suspicious(shop_dict, suspicious_list, shopid_list, curr_shopgrp_idx):\n",
    "    shop_dict[shopid_list[curr_shopgrp_idx]] = suspicious_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Solve the problem\n",
    "With the subroutines above completing our arsenal, we are now ready to tackle the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Variable initialization\n",
    "We initialize the containers that we will be using in the main routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array containing the indices of the first entries per shop\n",
    "shopgrp_idx_list = make_shopgrp_idx_list(shopid_list)\n",
    "\n",
    "# Dictionary containing the shop IDs as keys and the list of associated suspicious buyers as values\n",
    "shop_dict = {}\n",
    "\n",
    "# Dictionary containing the user IDs as keys and the set of associated order IDs as values\n",
    "transact_dict = defaultdict(set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Main routine\n",
    "In writing the main routine to solve the problem, it is important to point out that having the data sorted is a precondition.\n",
    "\n",
    "**Moreover, the case when start_time<sub>order &ndash; 1</sub> does not exist is handled in this step.** This warrants handling the first entry of each shop separately from the rest. As long as start_time<sub>order</sub> (the first entry of each shop) and end_time<sub>order</sub> are within 1 hour, then the conditions for a possible order brushing period are satisfied since we can set end_time<sub>true</sub> = end_time<sub>order</sub> and set start_time<sub>true</sub> to 1 hour before end_time<sub>true</sub>.\n",
    "\n",
    "Note that this logic still holds even if we change the length of the time window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over every shop. Each iteration corresponds to a unique shop ID.\n",
    "for i, curr_shopgrp_idx in enumerate(shopgrp_idx_list[:-1]):  \n",
    "    \n",
    "    # Index of the first entry of the next shop\n",
    "    next_shopgrp_idx = shopgrp_idx_list[i + 1]\n",
    "    \n",
    "    \n",
    "    # HANDLE THE FIRST ENTRY SEPARATELY AS EXPLAINED ABOVE.\n",
    "    start_time_idx = curr_shopgrp_idx\n",
    "    start_time = event_time_list[start_time_idx]\n",
    "    \n",
    "    # Iterate over every end time.\n",
    "    # We skip the first (BRUSH_NUM_ENTRIES - 1) entries since at least BRUSH_NUM_ENTRIES are needed\n",
    "    #     to constitute an order brushing period.\n",
    "    for end_time_idx, end_time in enumerate(event_time_list[start_time_idx + BRUSH_NUM_ENTRIES - 1 : next_shopgrp_idx], \n",
    "                                            start_time_idx + BRUSH_NUM_ENTRIES - 1):\n",
    "        \n",
    "        # If the start time and end time are already beyond the time window for an order brushing period,\n",
    "        #     we exit the loop and proceed to the next start time.\n",
    "        if not is_within_time(start_time, end_time, BRUSH_NUM_SECONDS):\n",
    "            break\n",
    "        \n",
    "        # Check if order brushing was conducted. \n",
    "        if is_order_brushing(concen_rate(userid_list, start_time_idx, end_time_idx), BRUSH_CONCEN_RATE):\n",
    "            \n",
    "            # Update transact_dict of the shop by iterating over all the entries in the period.\n",
    "            for userid, orderid in zip(userid_list[start_time_idx : end_time_idx + 1], \n",
    "                                       orderid_list[start_time_idx : end_time_idx + 1]):\n",
    "                transact_dict[userid].add(orderid)\n",
    "                    \n",
    "    \n",
    "    # HANDLE THE REMAINING ENTRIES.\n",
    "    \n",
    "    # Iterate over every start time.\n",
    "    # We only iterate until the (BRUSH_NUM_ENTRIES)th-to-the-last timestamp \n",
    "    #     since at least BRUSH_NUM_ENTRIES are needed to constitute an order brushing period.\n",
    "    for start_time_idx, start_time in enumerate(event_time_list[curr_shopgrp_idx + 1 : next_shopgrp_idx - BRUSH_NUM_ENTRIES + 1],\n",
    "                                                curr_shopgrp_idx + 1):\n",
    "        \n",
    "        # Iterate over every end time.\n",
    "        # We skip the first (BRUSH_NUM_ENTRIES - 1) entries since at least BRUSH_NUM_ENTRIES are needed\n",
    "        #     to constitute an order brushing period.\n",
    "        for end_time_idx, end_time in enumerate(event_time_list[start_time_idx + BRUSH_NUM_ENTRIES - 1 : next_shopgrp_idx], \n",
    "                                                start_time_idx + BRUSH_NUM_ENTRIES - 1):\n",
    "            \n",
    "            # If the start time and end time are already beyond the time window for an order brushing period,\n",
    "            #     we exit the loop and proceed to the next start time.\n",
    "            if not is_within_time(start_time, end_time, BRUSH_NUM_SECONDS):\n",
    "                break\n",
    "            \n",
    "            # Check if the period is a possible order brushing period and if order brushing was conducted.\n",
    "            if is_possible_brush_time(event_time_list, start_time_idx, end_time_idx, next_shopgrp_idx, BRUSH_NUM_SECONDS) \\\n",
    "            and is_order_brushing(concen_rate(userid_list, start_time_idx, end_time_idx), BRUSH_CONCEN_RATE): \n",
    "                \n",
    "                # Update transact_dict of the shop by iterating over all the entries in the period.\n",
    "                for userid, orderid in zip(userid_list[start_time_idx : end_time_idx + 1], \n",
    "                                           orderid_list[start_time_idx : end_time_idx + 1]):\n",
    "                    transact_dict[userid].add(orderid)\n",
    "    \n",
    "    \n",
    "    # Identify the suspicious buyers and update shop_dict.\n",
    "    assign_suspicious(shop_dict, get_suspicious(transact_dict), shopid_list, curr_shopgrp_idx)\n",
    "    \n",
    "    # Clear transact_dict in preparation for the next shop.\n",
    "    transact_dict.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity test, we display a table containing the shop IDs, the list of suspicious buyers, and the indices of the first and last entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(shop_dict.items(), columns = ['Shop ID', 'Suspicious Buyers'])\n",
    "results['Index of First Entry'] = shopgrp_idx_list[:-1]\n",
    "results['Index of Last Entry'] = shopgrp_idx_list[1:] - 1\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the submission file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the CSV file containing the results of our data analysis is the final step in the order brushing detection challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('order_brush_submission.csv', mode = 'w', newline = '') as file:\n",
    "    \n",
    "    # The names of the headers are included in the specifications.\n",
    "    header_names = ['shopid', 'userid']\n",
    "    \n",
    "    # Since the contents of the CSV file are derived from shop_dict, we use the DictWriter class,\n",
    "    #     which is tailored for Python dictionaries.\n",
    "    writer = csv.DictWriter(file, fieldnames = header_names)\n",
    "    \n",
    "    # Write the header: shopid,userid.\n",
    "    writer.writeheader()\n",
    "    \n",
    "    # Iterate over every item in shop_dict.\n",
    "    for shop, suspicious_list in shop_dict.items():\n",
    "        \n",
    "        # The user IDs are separated by an ampersand. There are no spaces before and after the ampersand. \n",
    "        # Since the user IDs are stored as integers, they should be converted to strings first.\n",
    "        user_str = '&'.join([str(user) for user in suspicious_list])\n",
    "        \n",
    "        # Each row should indicate the shop ID followed by the user IDs of the suspicious buyers.\n",
    "        # These two fields are separated by a comma (which is already the default). \n",
    "        writer.writerow({'shopid': shop, 'userid': user_str})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
